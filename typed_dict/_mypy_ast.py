from __future__ import annotations

from dataclasses import dataclass

from mypy import nodes, types
from mypy.plugin import SemanticAnalyzerPluginInterface

FALLBACKS = (
    'typing._TypedDict',
    'typing_extensions._TypedDict',
    'mypy_extensions._TypedDict',
)


@dataclass(frozen=True)
class Field:
    """Information about a TypedDict field."""

    name: str
    type: types.Type | None
    required: bool


@dataclass(frozen=True)
class Model:
    """Container for information required to build a TypedDict."""

    name: str
    fields: list[Field]

    @classmethod
    def from_dataclass(cls, target: nodes.TypeInfo) -> Model:
        """Parse dataclass mypy node into a Model.

        If the target is a name defined in the current file, the plugin is executed
        before mypy generates `__init__` for dataclass. In that case, we generate
        a Model from the statically defined class attributes.

        If the target is deifned in another already analyzed module,
        `__init__` is already generated by mypy, and we can use it.
        """
        if '__dataclass_fields__' in target.names:
            model = cls.from_init(target)
            if model is not None:
                return model
        return cls.from_attrs(target)

    @classmethod
    def from_attrs(cls, target: nodes.TypeInfo) -> Model:
        """Parse target class attributes into a Model."""
        fields = []
        for name, node in target.names.items():
            fields.append(Field(
                name=name,
                type=node.type,
                required=False,
            ))
        return cls(
            name=target.name,
            fields=fields,
        )

    @classmethod
    def from_init(cls, target: nodes.TypeInfo) -> Model | None:
        """Parse `__init__` method of the target class into a Model."""
        init = target.get_method('__init__')
        if not isinstance(init, nodes.FuncDef):
            return None
        if not isinstance(init.type, types.CallableType):
            return None
        return cls(
            name=target.name,
            fields=cls._field_from_callable(init.type, skip_self=True),
        )

    def as_type_info(
        self,
        api: SemanticAnalyzerPluginInterface,
        line: int,
    ) -> nodes.TypeInfo:
        """Represent the Model as TypeInfo for a TypedDict."""
        fallback = self._get_fallback(api)
        type_info = api.basic_new_typeinfo(self.name, fallback, line)
        any_type = api.lookup_fully_qualified('typing.Any').type
        assert any_type is not None
        type_info.update_typeddict_type(
            types.TypedDictType(
                items={f.name: f.type or any_type for f in self.fields},
                required_keys={f.name for f in self.fields if f.required},
                fallback=fallback,
            ),
        )
        return type_info

    @staticmethod
    def _field_from_callable(
        type_info: types.CallableType,
        *,
        skip_self: bool,
    ) -> list[Field]:
        fields = []
        args_info = zip(
            type_info.arg_names,
            type_info.arg_types,
            type_info.arg_kinds,
        )
        if skip_self and type_info.arg_names[0] == 'self':
            next(args_info)
        for aname, atype, akind in args_info:
            if aname is None:
                continue
            fields.append(Field(
                name=aname,
                type=atype,
                required=akind.is_required(),
            ))
        return fields

    def _get_fallback(
        self,
        api: SemanticAnalyzerPluginInterface,
    ) -> types.Instance:
        for name in FALLBACKS:
            fallback = api.named_type_or_none(name, [])
            if fallback is not None:
                return fallback
        raise LookupError('cannot find fallback type for TypedDict')
